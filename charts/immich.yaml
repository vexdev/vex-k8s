---
# Source: immich/templates/immich-namespace.yaml
apiVersion: v1
kind: Namespace
metadata:
  name: immich
---
# Source: immich/charts/immich/charts/redis/templates/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: release-name-redis
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.4.2
    helm.sh/chart: redis-20.11.3
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: redis
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    # Allow inbound connections
    - ports:
        - port: 6379
---
# Source: immich/charts/postgresql/templates/primary/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: release-name-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.4.0
    helm.sh/chart: postgresql-16.4.15
    app.kubernetes.io/component: primary
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    - ports:
        - port: 5432
---
# Source: immich/charts/immich/charts/redis/templates/master/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: release-name-redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.4.2
    helm.sh/chart: redis-20.11.3
    app.kubernetes.io/component: master
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: redis
      app.kubernetes.io/component: master
---
# Source: immich/charts/postgresql/templates/primary/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: release-name-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.4.0
    helm.sh/chart: postgresql-16.4.15
    app.kubernetes.io/component: primary
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
---
# Source: immich/charts/immich/charts/redis/templates/master/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: false
metadata:
  name: release-name-redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.4.2
    helm.sh/chart: redis-20.11.3
---
# Source: immich/charts/nfs-homes/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    chart: nfs-homes-4.0.18
    heritage: Helm
    app: nfs-homes
    release: release-name
  name: release-name-nfs-homes
---
# Source: immich/charts/nfs-photos/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  labels:
    chart: nfs-photos-4.0.18
    heritage: Helm
    app: nfs-photos
    release: release-name
  name: release-name-nfs-photos
---
# Source: immich/charts/postgresql/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: release-name-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.4.0
    helm.sh/chart: postgresql-16.4.15
automountServiceAccountToken: false
---
# Source: immich/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: release-name-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.4.0
    helm.sh/chart: postgresql-16.4.15
type: Opaque
data:
  postgres-password: "bDV1bml5VXE3dg=="
  password: "aW1taWNo"
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: immich/charts/immich/charts/redis/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis-configuration
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.4.2
    helm.sh/chart: redis-20.11.3
data:
  redis.conf: |-
    # User-supplied common configuration:
    # Enable AOF https://redis.io/topics/persistence#append-only-file
    appendonly yes
    # Disable RDB persistence, AOF persistence already enabled.
    save ""
    # End of common configuration
  master.conf: |-
    dir /data
    # User-supplied master configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of master configuration
  replica.conf: |-
    dir /data
    # User-supplied replica configuration:
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    # End of replica configuration
  users.acl: |-
---
# Source: immich/charts/immich/charts/redis/templates/health-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis-health
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.4.2
    helm.sh/chart: redis-20.11.3
data:
  ping_readiness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_local.sh: |-
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    [[ -n "$REDIS_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h localhost \
        -p $REDIS_PORT \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ] && [ "$responseFirstWord" != "MASTERDOWN" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
  ping_liveness_master.sh: |-
    #!/bin/bash

    [[ -f $REDIS_MASTER_PASSWORD_FILE ]] && export REDIS_MASTER_PASSWORD="$(< "${REDIS_MASTER_PASSWORD_FILE}")"
    [[ -n "$REDIS_MASTER_PASSWORD" ]] && export REDISCLI_AUTH="$REDIS_MASTER_PASSWORD"
    response=$(
      timeout -s 15 $1 \
      redis-cli \
        -h $REDIS_MASTER_HOST \
        -p $REDIS_MASTER_PORT_NUMBER \
        ping
    )
    if [ "$?" -eq "124" ]; then
      echo "Timed out"
      exit 1
    fi
    responseFirstWord=$(echo $response | head -n1 | awk '{print $1;}')
    if [ "$response" != "PONG" ] && [ "$responseFirstWord" != "LOADING" ]; then
      echo "$response"
      exit 1
    fi
  ping_readiness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_readiness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_readiness_master.sh" $1 || exit_status=$?
    exit $exit_status
  ping_liveness_local_and_master.sh: |-
    script_dir="$(dirname "$0")"
    exit_status=0
    "$script_dir/ping_liveness_local.sh" $1 || exit_status=$?
    "$script_dir/ping_liveness_master.sh" $1 || exit_status=$?
    exit $exit_status
---
# Source: immich/charts/immich/charts/redis/templates/scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-redis-scripts
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.4.2
    helm.sh/chart: redis-20.11.3
data:
  start-master.sh: |
    #!/bin/bash

    [[ -f $REDIS_PASSWORD_FILE ]] && export REDIS_PASSWORD="$(< "${REDIS_PASSWORD_FILE}")"
    if [[ -f /opt/bitnami/redis/mounted-etc/master.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/master.conf /opt/bitnami/redis/etc/master.conf
    fi
    if [[ -f /opt/bitnami/redis/mounted-etc/redis.conf ]];then
        cp /opt/bitnami/redis/mounted-etc/redis.conf /opt/bitnami/redis/etc/redis.conf
    fi
    if [[ -f /opt/bitnami/redis/mounted-etc/users.acl ]];then
        cp /opt/bitnami/redis/mounted-etc/users.acl /opt/bitnami/redis/etc/users.acl
    fi
    ARGS=("--port" "${REDIS_PORT}")
    ARGS+=("--protected-mode" "no")
    ARGS+=("--include" "/opt/bitnami/redis/etc/redis.conf")
    ARGS+=("--include" "/opt/bitnami/redis/etc/master.conf")
    exec redis-server "${ARGS[@]}"
---
# Source: immich/charts/postgresql/templates/primary/initialization-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: release-name-postgresql-init-scripts
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.4.0
    helm.sh/chart: postgresql-16.4.15
data:
  create-extensions.sql: |
    CREATE EXTENSION cube;
    CREATE EXTENSION earthdistance;
    CREATE EXTENSION vectors;
---
# Source: immich/charts/nfs-homes/templates/storageclass.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  labels:
    chart: nfs-homes-4.0.18
    heritage: Helm
    app: nfs-homes
    release: release-name
  name: nfs-nas-homes
  annotations:
provisioner: cluster.local/release-name-nfs-homes
allowVolumeExpansion: true
reclaimPolicy: Retain
volumeBindingMode: Immediate
parameters:
  archiveOnDelete: "false"
  pathPattern: "/"
  onDelete: "retain"
---
# Source: immich/charts/nfs-photos/templates/storageclass.yaml
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  labels:
    chart: nfs-photos-4.0.18
    heritage: Helm
    app: nfs-photos
    release: release-name
  name: nfs-photo
  annotations:
provisioner: cluster.local/release-name-nfs-photos
allowVolumeExpansion: true
reclaimPolicy: Retain
volumeBindingMode: Immediate
parameters:
  archiveOnDelete: "false"
  pathPattern: "${.PVC.name}"
  onDelete: "retain"
---
# Source: immich/templates/nas-homes-volume-claim.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nas-homes-volume-claim
spec:
  accessModes:
    - ReadOnlyMany
  storageClassName: nfs-nas-homes
  resources:
    requests:
      storage: 2Ti
---
# Source: immich/templates/photo-volume-claim.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: photo-volume-claim
spec:
  accessModes:
    - ReadWriteOnce
  storageClassName: nfs-photo
  resources:
    requests:
      storage: 2Ti
---
# Source: immich/charts/nfs-homes/templates/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    chart: nfs-homes-4.0.18
    heritage: Helm
    app: nfs-homes
    release: release-name
  name: release-name-nfs-homes-runner
rules:
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "create", "delete"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch", "update"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create", "update", "patch"]
---
# Source: immich/charts/nfs-photos/templates/clusterrole.yaml
kind: ClusterRole
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    chart: nfs-photos-4.0.18
    heritage: Helm
    app: nfs-photos
    release: release-name
  name: release-name-nfs-photos-runner
rules:
  - apiGroups: [""]
    resources: ["nodes"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["persistentvolumes"]
    verbs: ["get", "list", "watch", "create", "delete"]
  - apiGroups: [""]
    resources: ["persistentvolumeclaims"]
    verbs: ["get", "list", "watch", "update"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["storageclasses"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["create", "update", "patch"]
---
# Source: immich/charts/nfs-homes/templates/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    chart: nfs-homes-4.0.18
    heritage: Helm
    app: nfs-homes
    release: release-name
  name: run-release-name-nfs-homes
subjects:
  - kind: ServiceAccount
    name: release-name-nfs-homes
    namespace: default
roleRef:
  kind: ClusterRole
  name: release-name-nfs-homes-runner
  apiGroup: rbac.authorization.k8s.io
---
# Source: immich/charts/nfs-photos/templates/clusterrolebinding.yaml
kind: ClusterRoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    chart: nfs-photos-4.0.18
    heritage: Helm
    app: nfs-photos
    release: release-name
  name: run-release-name-nfs-photos
subjects:
  - kind: ServiceAccount
    name: release-name-nfs-photos
    namespace: default
roleRef:
  kind: ClusterRole
  name: release-name-nfs-photos-runner
  apiGroup: rbac.authorization.k8s.io
---
# Source: immich/charts/nfs-homes/templates/role.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    chart: nfs-homes-4.0.18
    heritage: Helm
    app: nfs-homes
    release: release-name
  name: leader-locking-release-name-nfs-homes
rules:
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]
---
# Source: immich/charts/nfs-photos/templates/role.yaml
kind: Role
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    chart: nfs-photos-4.0.18
    heritage: Helm
    app: nfs-photos
    release: release-name
  name: leader-locking-release-name-nfs-photos
rules:
  - apiGroups: [""]
    resources: ["endpoints"]
    verbs: ["get", "list", "watch", "create", "update", "patch"]
---
# Source: immich/charts/nfs-homes/templates/rolebinding.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    chart: nfs-homes-4.0.18
    heritage: Helm
    app: nfs-homes
    release: release-name
  name: leader-locking-release-name-nfs-homes
subjects:
  - kind: ServiceAccount
    name: release-name-nfs-homes
    namespace: default
roleRef:
  kind: Role
  name: leader-locking-release-name-nfs-homes
  apiGroup: rbac.authorization.k8s.io
---
# Source: immich/charts/nfs-photos/templates/rolebinding.yaml
kind: RoleBinding
apiVersion: rbac.authorization.k8s.io/v1
metadata:
  labels:
    chart: nfs-photos-4.0.18
    heritage: Helm
    app: nfs-photos
    release: release-name
  name: leader-locking-release-name-nfs-photos
subjects:
  - kind: ServiceAccount
    name: release-name-nfs-photos
    namespace: default
roleRef:
  kind: Role
  name: leader-locking-release-name-nfs-photos
  apiGroup: rbac.authorization.k8s.io
---
# Source: immich/charts/immich/charts/redis/templates/headless-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-redis-headless
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.4.2
    helm.sh/chart: redis-20.11.3
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: redis
---
# Source: immich/charts/immich/charts/redis/templates/master/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.4.2
    helm.sh/chart: redis-20.11.3
    app.kubernetes.io/component: master
spec:
  type: ClusterIP
  internalTrafficPolicy: Cluster
  sessionAffinity: None
  ports:
    - name: tcp-redis
      port: 6379
      targetPort: redis
      nodePort: null
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: redis
    app.kubernetes.io/component: master
---
# Source: immich/charts/immich/templates/machine-learning.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-machine-learning
  labels:
    app.kubernetes.io/service: release-name-machine-learning
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: machine-learning
    app.kubernetes.io/version: v1.119.0
    helm.sh/chart: immich-0.9.2
  annotations:
spec:
  type: ClusterIP
  ports:
    - port: 3003
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: machine-learning
---
# Source: immich/charts/immich/templates/server.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-server
  labels:
    app.kubernetes.io/service: release-name-server
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: server
    app.kubernetes.io/version: v1.119.0
    helm.sh/chart: immich-0.9.2
  annotations:
spec:
  type: ClusterIP
  ports:
    - port: 2283
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: server
---
# Source: immich/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql-hl
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.4.0
    helm.sh/chart: postgresql-16.4.15
    app.kubernetes.io/component: primary
  annotations:
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: immich/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: release-name-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.4.0
    helm.sh/chart: postgresql-16.4.15
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: immich/charts/immich/templates/machine-learning.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-machine-learning
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: machine-learning
    app.kubernetes.io/version: v1.119.0
    helm.sh/chart: immich-0.9.2
spec:
  revisionHistoryLimit: 3
  replicas: 1
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: machine-learning
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: machine-learning
        app.kubernetes.io/instance: release-name
    spec:
      
      serviceAccountName: default
      automountServiceAccountToken: true
      dnsPolicy: ClusterFirst
      enableServiceLinks: true
      containers:
        - name: release-name-machine-learning
          image: ghcr.io/immich-app/immich-machine-learning:v1.131.3
          imagePullPolicy: IfNotPresent
          env:
            - name: DB_DATABASE_NAME
              value: immich
            - name: DB_HOSTNAME
              value: release-name-postgresql
            - name: DB_PASSWORD
              value: immich
            - name: DB_USERNAME
              value: immich
            - name: IMMICH_MACHINE_LEARNING_URL
              value: http://release-name-machine-learning:3003
            - name: REDIS_HOSTNAME
              value: release-name-redis-master
            - name: TRANSFORMERS_CACHE
              value: /cache
          ports:
            - name: http
              containerPort: 3003
              protocol: TCP
          volumeMounts:
            - name: cache
              mountPath: /cache
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /ping
              port: http
            initialDelaySeconds: 0
            periodSeconds: 10
            timeoutSeconds: 1
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /ping
              port: http
            initialDelaySeconds: 0
            periodSeconds: 10
            timeoutSeconds: 1
          startupProbe:
            failureThreshold: 60
            httpGet:
              path: /ping
              port: http
            initialDelaySeconds: 0
            periodSeconds: 10
            timeoutSeconds: 1
      volumes:
        - name: cache
          emptyDir:
            {}
      nodeSelector:
        vex.location: swisshome
---
# Source: immich/charts/immich/templates/server.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-server
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: server
    app.kubernetes.io/version: v1.119.0
    helm.sh/chart: immich-0.9.2
spec:
  revisionHistoryLimit: 3
  replicas: 1
  strategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: server
      app.kubernetes.io/instance: release-name
  template:
    metadata:
      labels:
        app.kubernetes.io/name: server
        app.kubernetes.io/instance: release-name
    spec:
      
      serviceAccountName: default
      automountServiceAccountToken: true
      dnsPolicy: ClusterFirst
      enableServiceLinks: true
      containers:
        - name: release-name-server
          image: ghcr.io/immich-app/immich-server:v1.131.3
          imagePullPolicy: IfNotPresent
          env:
            - name: DB_DATABASE_NAME
              value: immich
            - name: DB_HOSTNAME
              value: release-name-postgresql
            - name: DB_PASSWORD
              value: immich
            - name: DB_USERNAME
              value: immich
            - name: DB_VECTOR_EXTENSION
              value: pgvector
            - name: IMMICH_LOG_LEVEL
              value: verbose
            - name: IMMICH_MACHINE_LEARNING_URL
              value: http://release-name-machine-learning:3003
            - name: REDIS_HOSTNAME
              value: release-name-redis-master
          ports:
            - name: http
              containerPort: 2283
              protocol: TCP
          volumeMounts:
            - name: library
              mountPath: /usr/src/app/upload
            - name: synology
              mountPath: /synology
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /api/server/ping
              port: http
            initialDelaySeconds: 0
            periodSeconds: 10
            timeoutSeconds: 1
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /api/server/ping
              port: http
            initialDelaySeconds: 0
            periodSeconds: 10
            timeoutSeconds: 1
          startupProbe:
            failureThreshold: 30
            httpGet:
              path: /api/server/ping
              port: http
            initialDelaySeconds: 0
            periodSeconds: 10
            timeoutSeconds: 1
      volumes:
        - name: library
          persistentVolumeClaim:
            claimName: photo-volume-claim
        - name: synology
          persistentVolumeClaim:
            claimName: nas-homes-volume-claim
      nodeSelector:
        vex.location: swisshome
---
# Source: immich/charts/nfs-homes/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-nfs-homes
  labels:
    chart: nfs-homes-4.0.18
    heritage: Helm
    app: nfs-homes
    release: release-name
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: nfs-homes
      release: release-name
  template:
    metadata:
      annotations:
      labels:
        app: nfs-homes
        release: release-name
    spec:
      serviceAccountName: release-name-nfs-homes
      securityContext:
        {}
      nodeSelector:
        vex.location: swisshome
      containers:
        - name: nfs-homes
          image: "registry.k8s.io/sig-storage/nfs-subdir-external-provisioner:v4.0.2"
          imagePullPolicy: IfNotPresent
          securityContext:
            {}
          volumeMounts:
            - name: nfs-subdir-external-provisioner-root
              mountPath: /persistentvolumes
          env:
            - name: PROVISIONER_NAME
              value: cluster.local/release-name-nfs-homes
            - name: NFS_SERVER
              value: 100.91.224.51
            - name: NFS_PATH
              value: /volume1/homes
      volumes:
        - name: nfs-subdir-external-provisioner-root
          nfs:
            server: 100.91.224.51
            path: /volume1/homes
---
# Source: immich/charts/nfs-photos/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: release-name-nfs-photos
  labels:
    chart: nfs-photos-4.0.18
    heritage: Helm
    app: nfs-photos
    release: release-name
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: nfs-photos
      release: release-name
  template:
    metadata:
      annotations:
      labels:
        app: nfs-photos
        release: release-name
    spec:
      serviceAccountName: release-name-nfs-photos
      securityContext:
        {}
      nodeSelector:
        vex.location: swisshome
      containers:
        - name: nfs-photos
          image: "registry.k8s.io/sig-storage/nfs-subdir-external-provisioner:v4.0.2"
          imagePullPolicy: IfNotPresent
          securityContext:
            {}
          volumeMounts:
            - name: nfs-subdir-external-provisioner-root
              mountPath: /persistentvolumes
          env:
            - name: PROVISIONER_NAME
              value: cluster.local/release-name-nfs-photos
            - name: NFS_SERVER
              value: 100.91.224.51
            - name: NFS_PATH
              value: /volume1/photo
      volumes:
        - name: nfs-subdir-external-provisioner-root
          nfs:
            server: 100.91.224.51
            path: /volume1/photo
---
# Source: immich/charts/immich/charts/redis/templates/master/application.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-redis-master
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: redis
    app.kubernetes.io/version: 7.4.2
    helm.sh/chart: redis-20.11.3
    app.kubernetes.io/component: master
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: redis
      app.kubernetes.io/component: master
  serviceName: release-name-redis-headless
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: redis
        app.kubernetes.io/version: 7.4.2
        helm.sh/chart: redis-20.11.3
        app.kubernetes.io/component: master
      annotations:
        checksum/configmap: 2a9ab4a5432825504d910f022638674ce88eaefe9f9f595ad8bc107377d104fb
        checksum/health: aff24913d801436ea469d8d374b2ddb3ec4c43ee7ab24663d5f8ff1a1b6991a9
        checksum/scripts: bdec350b84a1ace7cc118db113a21c9f160bde3425b07714e1c0c1da722621cf
        checksum/secret: 44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a
    spec:
      
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      serviceAccountName: release-name-redis-master
      automountServiceAccountToken: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/name: redis
                    app.kubernetes.io/component: master
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      nodeSelector:
        vex.location: swisshome
      enableServiceLinks: true
      terminationGracePeriodSeconds: 30
      containers:
        - name: redis
          image: docker.io/bitnami/redis:7.4.2-debian-12-r4
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          command:
            - /bin/bash
          args:
            - -c
            - /opt/bitnami/scripts/start-scripts/start-master.sh
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: REDIS_REPLICATION_MODE
              value: master
            - name: ALLOW_EMPTY_PASSWORD
              value: "yes"
            - name: REDIS_TLS_ENABLED
              value: "no"
            - name: REDIS_PORT
              value: "6379"
          ports:
            - name: redis
              containerPort: 6379
          livenessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            # One second longer than command timeout should prevent generation of zombie processes.
            timeoutSeconds: 6
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_liveness_local.sh 5
          readinessProbe:
            initialDelaySeconds: 20
            periodSeconds: 5
            timeoutSeconds: 2
            successThreshold: 1
            failureThreshold: 5
            exec:
              command:
                - sh
                - -c
                - /health/ping_readiness_local.sh 1
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 2Gi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
          volumeMounts:
            - name: start-scripts
              mountPath: /opt/bitnami/scripts/start-scripts
            - name: health
              mountPath: /health
            - name: redis-data
              mountPath: /data
            - name: config
              mountPath: /opt/bitnami/redis/mounted-etc
            - name: empty-dir
              mountPath: /opt/bitnami/redis/etc/
              subPath: app-conf-dir
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
      volumes:
        - name: start-scripts
          configMap:
            name: release-name-redis-scripts
            defaultMode: 0755
        - name: health
          configMap:
            name: release-name-redis-health
            defaultMode: 0755
        - name: config
          configMap:
            name: release-name-redis-configuration
        - name: empty-dir
          emptyDir: {}
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: redis-data
        labels:
          app.kubernetes.io/instance: release-name
          app.kubernetes.io/name: redis
          app.kubernetes.io/component: master
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
        storageClassName: local-path
---
# Source: immich/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: release-name-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: release-name
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 17.4.0
    helm.sh/chart: postgresql-16.4.15
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: release-name-postgresql-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/instance: release-name
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: release-name-postgresql
      labels:
        app.kubernetes.io/instance: release-name
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: postgresql
        app.kubernetes.io/version: 17.4.0
        helm.sh/chart: postgresql-16.4.15
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: release-name-postgresql
      
      automountServiceAccountToken: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: release-name
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      nodeSelector:
        vex.location: swisshome
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      hostNetwork: false
      hostIPC: false
      containers:
        - name: postgresql
          image: docker.io/pgvector/pgvector:0.8.0-pg17
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: false
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_USER
              value: "immich"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: password
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: release-name-postgresql
                  key: postgres-password
            - name: POSTGRES_DATABASE
              value: "immich"
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "immich" -d "dbname=immich" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "immich" -d "dbname=immich" -h 127.0.0.1 -p 5432
          resources:
            requests:
              cpu: 500m
              memory: 1Gi
          volumeMounts:
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: empty-dir
              mountPath: /opt/bitnami/postgresql/conf
              subPath: app-conf-dir
            - name: empty-dir
              mountPath: /opt/bitnami/postgresql/tmp
              subPath: app-tmp-dir
            - name: custom-init-scripts
              mountPath: /docker-entrypoint-initdb.d/
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: empty-dir
          emptyDir: {}
        - name: custom-init-scripts
          configMap:
            name: release-name-postgresql-init-scripts
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: immich/templates/photos-ingress-tls.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: photos-tls-ingress
  annotations:
    cert-manager.io/cluster-issuer: letsencrypt-prod
    traefik.ingress.kubernetes.io/router.entrypoints: websecure
    traefik.ingress.kubernetes.io/router.tls: "true"
    traefik.ingress.kubernetes.io/service.serverScheme: http  # Ensure HTTP backend
    traefik.ingress.kubernetes.io/router.middlewares: default-default-headers@kubernetescrd  # Fix WebSocket and headers
spec:
  ingressClassName: traefik
  rules:
    - host: photos.vexdev.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: immich-server
                port:
                  number: 2283
  tls:
    - secretName: photos-tls
      hosts:
        - photos.vexdev.com
